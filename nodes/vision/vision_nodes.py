"""Vision Agent ë…¸ë“œ í•¨ìˆ˜ë“¤"""
from routing.routers import vision_router
from core.llm_config import llm_vision
from sar_segmentation_node import run_sar_segmentation, sar_segmentation_generate
import vision_tools


def vision_task_router(state):
    """Vision ì‘ì—… ë¼ìš°íŒ…: segmentation, classification, detection ì¤‘ ì„ íƒ"""
    print("==== [VISION TASK ROUTER] ====")
    question = state.get("question", "")
    
    # ëª…ì‹œì  í‚¤ì›Œë“œ ì²´í¬ (ìš°ì„ ìˆœìœ„)
    if any(kw in question.lower() for kw in ["segmentation", "ë¶„í• ", "lulc", "land cover"]):
        print("==== [Segmentation í‚¤ì›Œë“œ ê°ì§€ - SELECTED TASK: segmentation] ====")
        return "segmentation"
    elif any(kw in question.lower() for kw in ["classification", "ë¶„ë¥˜", "classify"]):
        print("==== [Classification í‚¤ì›Œë“œ ê°ì§€ - SELECTED TASK: classification] ====")
        return "classification"
    elif any(kw in question.lower() for kw in ["detection", "íƒì§€", "detect", "ì°¾ê¸°", "finding"]):
        print("==== [Detection í‚¤ì›Œë“œ ê°ì§€ - SELECTED TASK: detection] ====")
        return "detection"
    
    try:
        messages = state.get("messages", [])
        summary = state.get("summary", "")  # âœ… Summary ê°€ì ¸ì˜¤ê¸°
        result = vision_router.invoke({
            "question": question,
            "messages": messages,
            "summary": summary  # âœ… Summary ì „ë‹¬
        })
        task = result.task
        print(f"==== [SELECTED TASK: {task}] ====")
        
        if task == "segmentation":
            return "segmentation"
        elif task == "classification":
            return "classification"
        else:  # detection
            return "detection"
    except Exception as e:
        print(f"==== [ERROR in vision_task_router: {e}, defaulting to segmentation] ====")
        return "segmentation"


def run_segmentation(state):
    """Segmentation Tool ì§ì ‘ í˜¸ì¶œ (SAR ì´ë¯¸ì§€ëŠ” ai-service API ì‚¬ìš©)"""
    print("==== [RUN SEGMENTATION] ====")
    image_path = state.get("image_path", "")
    question = state.get("question", "")
    use_gt = state.get("use_gt", True)  # ê¸°ë³¸ì ìœ¼ë¡œ GT ëª¨ë“œ ì‚¬ìš©
    
    print(f"[DEBUG] stateì—ì„œ ë°›ì€ image_path: {image_path}")
    print(f"[DEBUG] image_path íƒ€ì…: {type(image_path)}")
    print(f"[DEBUG] question: {question}")
    
    if not image_path:
        error_msg = "ì´ë¯¸ì§€ ê²½ë¡œê°€ state.image_pathì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LangGraph Studioì—ì„œ image_path ì…ë ¥ í•„ë“œì— ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return {"vision_result": {"error": error_msg, "status": "no_image_path"}}
    
    # SAR ì´ë¯¸ì§€ ê°ì§€
    image_path_lower = image_path.lower()
    is_sar_image = (
        "_s1_" in image_path_lower or 
        "sentinel-1" in image_path_lower or 
        "/s1/" in image_path_lower or
        "sar" in image_path_lower
    )
    
    if is_sar_image:
        print("==== [SAR ì´ë¯¸ì§€ ê°ì§€ - ai-service API ì‚¬ìš©] ====")
        return run_sar_segmentation(state)
    
    # ì¼ë°˜ ì´ë¯¸ì§€ëŠ” ê¸°ì¡´ vision_tools ì‚¬ìš©
    try:
        print(f"[INFO] Segmentation ì²˜ë¦¬ ì‹œì‘: {image_path}")
        result = vision_tools.segmentation_tool.invoke(image_path)
        print(f"[INFO] Segmentation ê²°ê³¼: {result}")
        
        # toolì—ì„œ ë°˜í™˜í•œ ì—ëŸ¬ í™•ì¸
        if isinstance(result, dict) and "error" in result:
            print(f"[WARNING] Toolì—ì„œ ì—ëŸ¬ ë°˜í™˜: {result}")
            return {"vision_result": result}
        
        if not result or (isinstance(result, dict) and not result.get("output_path")):
            print(f"[WARNING] Segmentation ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ output_pathê°€ ì—†ìŒ")
            return {"vision_result": {"error": "Segmentation ì²˜ë¦¬ëŠ” ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", "status": "empty_result"}}
        
        return {"vision_result": result}
    except Exception as e:
        print(f"[ERROR] Segmentation ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"vision_result": {"error": f"Segmentation ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", "status": "failed"}}


def run_classification(state):
    """Classification Tool ì§ì ‘ í˜¸ì¶œ"""
    print("==== [RUN CLASSIFICATION] ====")
    image_path = state.get("image_path", "")
    
    if not image_path:
        error_msg = "ì´ë¯¸ì§€ ê²½ë¡œê°€ state.image_pathì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LangGraph Studioì—ì„œ image_path ì…ë ¥ í•„ë“œì— ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return {"vision_result": {"error": error_msg, "status": "no_image_path"}}
    
    try:
        print(f"[INFO] Classification ì²˜ë¦¬ ì‹œì‘: {image_path}")
        result = vision_tools.classification_tool.invoke(image_path)
        print(f"[INFO] Classification ê²°ê³¼: {result}")
        
        # toolì—ì„œ ë°˜í™˜í•œ ì—ëŸ¬ í™•ì¸
        if isinstance(result, dict) and "error" in result:
            print(f"[WARNING] Toolì—ì„œ ì—ëŸ¬ ë°˜í™˜: {result}")
            return {"vision_result": result}
        
        return {"vision_result": result}
    except Exception as e:
        print(f"[ERROR] Classification ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"vision_result": {"error": f"Classification ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", "status": "failed"}}


def run_detection(state):
    """Detection Tool ì§ì ‘ í˜¸ì¶œ"""
    print("==== [RUN DETECTION] ====")
    image_path = state.get("image_path", "")
    
    if not image_path:
        error_msg = "ì´ë¯¸ì§€ ê²½ë¡œê°€ state.image_pathì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LangGraph Studioì—ì„œ image_path ì…ë ¥ í•„ë“œì— ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return {"vision_result": {"error": error_msg, "status": "no_image_path"}}
    
    try:
        print(f"[INFO] Detection ì²˜ë¦¬ ì‹œì‘: {image_path}")
        result = vision_tools.detection_tool.invoke(image_path)
        print(f"[INFO] Detection ê²°ê³¼: {result}")
        
        # toolì—ì„œ ë°˜í™˜í•œ ì—ëŸ¬ í™•ì¸
        if isinstance(result, dict) and "error" in result:
            print(f"[WARNING] Toolì—ì„œ ì—ëŸ¬ ë°˜í™˜: {result}")
            return {"vision_result": result}
        
        return {"vision_result": result}
    except Exception as e:
        print(f"[ERROR] Detection ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"vision_result": {"error": f"Detection ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", "status": "failed"}}


def vision_generate(state):
    """Vision Tool ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±"""
    print("==== [VISION GENERATE] ====")
    question = state.get("question", "")
    vision_result = state.get("vision_result", {})
    messages = state.get("messages", [])
    summary = state.get("summary", "")  # âœ… Summary ê°€ì ¸ì˜¤ê¸°
    
    # ì—ëŸ¬ ì²´í¬
    if "error" in vision_result:
        error_msg = vision_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        status = vision_result.get("status", "failed")
        
        # ì´ë¯¸ì§€ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
        if status == "no_image_path":
            generation = f"""
âŒ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

**LangGraph Studio ì‚¬ìš© ë°©ë²•:**
1. ì…ë ¥ ì°½ ìƒë‹¨ì— `image_path` í•„ë“œê°€ ìˆìŠµë‹ˆë‹¤
2. í•´ë‹¹ í•„ë“œì— ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”
   ì˜ˆ: `/home/mjh/Project/LLM/RAG/files/test_folder/ROIs0000_test_s1_0_p1004.tif`
3. `question` í•„ë“œì—ëŠ” ì›í•˜ëŠ” ì‘ì—…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”
   ì˜ˆ: "SAR ì´ë¯¸ì§€ ë¶„í•  í•´ì¤˜"

**ì…ë ¥ ì˜ˆì‹œ:**
```json
{{
  "question": "SAR ì´ë¯¸ì§€ ë¶„í•  í•´ì¤˜",
  "image_path": "/home/mjh/Project/LLM/RAG/files/test_folder/ROIs0000_test_s1_0_p1004.tif"
}}
```
"""
        elif status == "connection_error":
            server_url = vision_result.get("server_url", "Unknown")
            generation = f"""
âŒ FastAPI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**ì„œë²„ ì£¼ì†Œ:** {server_url}

**í•´ê²° ë°©ë²•:**
1. FastAPI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   ```bash
   # ì„œë²„ ì‹¤í–‰ ëª…ë ¹ ì˜ˆì‹œ
   cd /home/mjh/Project/LLM/RAG/ai-service
   uvicorn app.main:app --host 192.168.10.174 --port 6600
   ```

2. ì„œë²„ ì£¼ì†Œì™€ í¬íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - í˜„ì¬ ì„¤ì •: {server_url}
   - vision_tools.pyì˜ FASTAPI_BASE_URL í™•ì¸

3. ë°©í™”ë²½ì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”

4. ì„œë²„ ìƒíƒœ í™•ì¸:
   ```bash
   curl {server_url}/health
   ```
"""
        else:
            generation = f"""
âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ë‚´ìš©:** {error_msg}

**í•´ê²° ë°©ë²•:**
1. ì´ë¯¸ì§€ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. íŒŒì¼ í˜•ì‹ì´ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš” (PNG, JPG, TIFF)
4. íŒŒì¼ì— ì½ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
"""
        return {"generation": generation, "previous_question": question}
    
    # SAR Segmentation ê²°ê³¼ ê°ì§€ (lulc_summary í•„ë“œê°€ ìˆìœ¼ë©´ SAR ê²°ê³¼)
    if "lulc_summary" in vision_result:
        return sar_segmentation_generate(state)
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ (LangGraph Studioì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë„ë¡)
    output_path = vision_result.get("output_path", "")
    analysis_result = vision_result.get("analysis_result", {})
    
    # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
    if not output_path and not analysis_result:
        generation = """
ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì›ì¸:
1. ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹ì´ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì§€ì› í˜•ì‹: PNG, JPG, TIFF)
2. ì´ë¯¸ì§€ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
3. AI ëª¨ë¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤

ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
"""
        return {"generation": generation, "previous_question": question}
    
    # ì •ìƒ ì²˜ë¦¬ - LLMìœ¼ë¡œ ì¹œì ˆí•œ ì„¤ëª… ìƒì„±
    summary_prefix = f"[ì´ì „ ëŒ€í™” ìš”ì•½]\n{summary}\n\n" if summary else ""
    final_prompt = f"""
{summary_prefix}ì‚¬ìš©ì ì§ˆë¬¸: {question}

AI ë¶„ì„ ê²°ê³¼:
{analysis_result}

ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œ: {output_path}

ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ë¶„ì„ ê²°ê³¼ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
"""
    
    response = llm_vision.invoke(final_prompt)
    generation = response.content if hasattr(response, 'content') else str(response)
    
    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ generationì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
    if output_path:
        generation += f"\n\nğŸ“ ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œ: {output_path}"
    
    return {"generation": generation, "previous_question": question}
